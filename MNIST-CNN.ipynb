{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Lambda, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam, SGD, Optimizer\n",
    "from keras.legacy import interfaces\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SGDR_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Download & preprocess MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras model needs one more dimension for number of channels.<br>\n",
    "MNIST data has only one channel, so expand one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(X_test,3)\n",
    "X_train = np.expand_dims(X_train,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onehot encode the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = enc.transform(y_train.reshape(-1, 1))\n",
    "y_test = enc.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ImageDataGenerator` to make `batches` and `test_bathces`.<br>\n",
    "Then make `batches` and `test_batches`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3000\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_batches = image.ImageDataGenerator().flow(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data should be normalized before get into the model.<br>\n",
    "Compute mean and standard deviation of training input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function which return normalized input data.<br>\n",
    "This function will be used as an input layer of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(28, 28, 1)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get SGD and SGDR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd = get_model()\n",
    "model_sgdr = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy weight of `model_sgd` to `model_sgdr` to make identical initial starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model_sgd.get_weights()\n",
    "model_sgdr.set_weights(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = 'weights/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since keras record training history only once per one epoch, number of epochs should be changed if moreh history information is needed.<br>\n",
    "`get_epochs` function returns hypothetical number of epochs given real number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epochs(n_epochs): return int(n_epochs * n_batch / steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_batch` shows the number of batches in full dataset.<br>\n",
    "Since number of data sample is 60000, `n_batch` will equal to 60000 / `batch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = len(batches); n_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After `n_batch` iterations, model trained for one real epoch.<br>\n",
    "After `steps_per_epoch` iterations, model trained for one hypothetical epoch, therefore record training history information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train SGD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a list which will record the training history information of SGD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_hist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`steps_per_epoch` defines number of steps for one hypothetical epoch.<br>\n",
    "Note that one real epoch is one cycle of full training data.<br>\n",
    "If `steps_per_epoch` is small, than Keras will record training history information more ofthen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model with SGD optimizer and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1)\n",
    "model_sgd.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd_hist.append(model_sgd.fit_generator(batches, epochs=get_epochs(200),\n",
    "                                        validation_data=test_batches, steps_per_epoch=steps_per_epoch, verbose=1))\n",
    "model_sgd.evaluate_generator(batches)[1], model_sgd.evaluate_generator(test_batches)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is over!<br>\n",
    "Save the weights of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_sgd.save_weights(f'{weight_path}mnist-sgd{model_index}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_sgd.load_weights(f'{weight_path}mnist-sgd{model_index}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train SGDR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 10\n",
    "lr = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iter_per_epoch` of SGDR defines the number of iterations of one cycle of learning rate.<br>\n",
    "If its same with `n_batch`, which is the number of iterations for one real epoch, then SGDR reset the learning rate for every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDR_keras.SGDR(lr=lr, iter_per_epoch=n_batch)\n",
    "model_sgdr.compile(sgdr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdr_hist.append(model_sgdr.fit_generator(batches, epochs=get_epochs(1),\n",
    "                                          validation_data=test_batches, steps_per_epoch=steps_per_epoch, verbose=1))\n",
    "model_sgdr.evaluate_generator(batches)[1], model_sgdr.evaluate_generator(test_batches)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDR_keras.SGDR(lr=lr, iter_per_epoch=2*n_batch)\n",
    "model_sgdr.compile(sgdr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdr_hist.append(model_sgdr.fit_generator(batches, epochs=get_epochs(2),\n",
    "                                          validation_data=test_batches, steps_per_epoch=steps_per_epoch, verbose=1))\n",
    "model_sgdr.evaluate_generator(batches)[1], model_sgdr.evaluate_generator(test_batches)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDR_keras.SGDR(lr=lr, iter_per_epoch=4*n_batch)\n",
    "model_sgdr.compile(sgdr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdr_hist.append(model_sgdr.fit_generator(batches, epochs=get_epochs(4),\n",
    "                                          validation_data=test_batches, steps_per_epoch=steps_per_epoch, verbose=1))\n",
    "model_sgdr.evaluate_generator(batches)[1], model_sgdr.evaluate_generator(test_batches)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDR_keras.SGDR(lr=lr, iter_per_epoch=8*n_batch)\n",
    "model_sgdr.compile(sgdr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdr_hist.append(model_sgdr.fit_generator(batches, epochs=get_epochs(8),\n",
    "                                          validation_data=test_batches, steps_per_epoch=steps_per_epoch, verbose=1))\n",
    "model_sgdr.evaluate_generator(batches)[1], model_sgdr.evaluate_generator(test_batches)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDR_keras.SGDR(lr=lr, iter_per_epoch=16*n_batch)\n",
    "model_sgdr.compile(sgdr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdr_hist.append(model_sgdr.fit_generator(batches, epochs=get_epochs(15),\n",
    "                                          validation_data=test_batches, steps_per_epoch=steps_per_epoch, verbose=1))\n",
    "model_sgdr.evaluate_generator(batches)[1], model_sgdr.evaluate_generator(test_batches)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDR_keras.SGDR(lr=lr, iter_per_epoch=32*n_batch)\n",
    "model_sgdr.compile(sgdr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdr_hist.append(model_sgdr.fit_generator(batches, epochs=get_epochs(31),\n",
    "                                          validation_data=test_batches, steps_per_epoch=steps_per_epoch, verbose=1))\n",
    "model_sgdr.evaluate_generator(batches)[1], model_sgdr.evaluate_generator(test_batches)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdr = SGDR_keras.SGDR(lr=lr, iter_per_epoch=64*n_batch)\n",
    "model_sgdr.compile(sgdr, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgdr_hist.append(model_sgdr.fit_generator(batches, epochs=get_epochs(63),\n",
    "                                          validation_data=test_batches, steps_per_epoch=steps_per_epoch, verbose=1))\n",
    "model_sgdr.evaluate_generator(batches)[1], model_sgdr.evaluate_generator(test_batches)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is over!<br>\n",
    "Save the weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_sgdr.save_weights(f'sgdr{model_index}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_sgdr.load_weights(f'{weight_path}mnist-sgdr{model_index}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(result, plot_type='loss', title='enter title!'):\n",
    "    train_res, test_res = [], []\n",
    "    \n",
    "    for hist in result:\n",
    "        train_res = train_res + hist.history[plot_type]\n",
    "        test_res = test_res + hist.history[f'val_{plot_type}']\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(title, size=15)\n",
    "    plt.plot(train_res)\n",
    "    plt.plot(test_res)\n",
    "    plt.ylabel(plot_type)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_hist(sgd_hist, 'loss', 'SGD loss')\n",
    "plt.ylim(0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(sgd_hist, 'acc', 'SGD Accuracy')\n",
    "plt.ylim(0.7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(sgdr_hist, 'loss', 'SGDR loss')\n",
    "plt.ylim(0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(sgdr_hist, 'acc', 'SGDR Accuracy')\n",
    "plt.ylim(0.7, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. filter normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make_direction` function returns filter-normalized randomly generated direction corresponed to given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_direction(model):\n",
    "    direction = []\n",
    "    for l in model.layers:\n",
    "        w = l.get_weights()\n",
    "        \n",
    "        #if layer is convolutional layer\n",
    "        if isinstance(l, Conv2D):\n",
    "            #make direction array\n",
    "            filter_w = np.zeros(w[0].shape)\n",
    "            bias_w = np.zeros(w[1].shape)\n",
    "\n",
    "            for f in range(l.filters):\n",
    "                for i in range(l.input_shape[3]):\n",
    "                    #randomly generate direction\n",
    "                    temp_direction = np.random.normal(size=w[0][:,:,i,f].shape)\n",
    "                    temp_bias = np.random.normal(size=w[1][f].shape)\n",
    "\n",
    "                    #compute norm of direction and original filter\n",
    "                    norm_model = np.linalg.norm(w[0][:,:,i,f], ord='fro')\n",
    "                    norm_direction = np.linalg.norm(temp_direction, ord='fro')\n",
    "\n",
    "                    #normalize generated direction\n",
    "                    temp_direction = temp_direction / norm_direction * norm_model\n",
    "                    temp_bias = temp_bias / norm_direction * norm_model\n",
    "\n",
    "                    #put generated one-filter direction to array\n",
    "                    filter_w[:,:,i,f] = temp_direction\n",
    "                    bias_w[f] = temp_bias\n",
    "\n",
    "            #append generate one-layer direction to direction list\n",
    "            direction.append(filter_w)\n",
    "            direction.append(bias_w)\n",
    "            \n",
    "        #if layer is FC\n",
    "        elif isinstance(l, Dense):\n",
    "            \n",
    "            #randomly generate direction\n",
    "            temp_direction = np.random.normal(size=w[0].shape)\n",
    "            temp_bias = np.random.normal(size=w[1].shape)\n",
    "            \n",
    "            #compute norm of direction and original layer\n",
    "            norm_model = np.linalg.norm(w[0], ord='fro')\n",
    "            norm_direction = np.linalg.norm(temp_direction, ord='fro')\n",
    "            \n",
    "            #normalize generated direction\n",
    "            temp_direction = temp_direction / norm_direction * norm_model\n",
    "            temp_bias = temp_bias / norm_direction * norm_model\n",
    "            \n",
    "            #put generated one-layer direction to array\n",
    "            direction.append(temp_direction)\n",
    "            direction.append(temp_bias)\n",
    "            \n",
    "        #if layer is BN\n",
    "        elif isinstance(l, BatchNormalization):\n",
    "            \n",
    "            temp_direction_list = []\n",
    "            \n",
    "            #randomly generate direction\n",
    "            for i in range(len(w)):\n",
    "                temp_direction_list.append(np.zeros(w[i].shape))\n",
    "            \n",
    "            \n",
    "            #put generated one-layer direction to array\n",
    "            for d in temp_direction_list:\n",
    "                direction.append(d)\n",
    "            \n",
    "    return direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`direction_step` function returns model of which weight is alpha * direction + original_model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_step(direction, model, alpha):\n",
    "    \n",
    "    step_model = get_model()\n",
    "    step_model.compile(sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    #get original model weights\n",
    "    weight = model.get_weights()\n",
    "    \n",
    "    new_weights = []\n",
    "    for i, w in enumerate(weight):\n",
    "        new_weights.append(w + alpha * direction[i])\n",
    "        \n",
    "    step_model.set_weights(new_weights)\n",
    "    \n",
    "    return step_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 1-D FN plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = make_direction(model_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.linspace(-1, 1, num=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_1d_fn(model, alpha_list, direction):\n",
    "    loss_train, acc_train = [], []\n",
    "    loss_test, acc_test = [], []\n",
    "#     direction = make_direction(model)\n",
    "    \n",
    "    for a in tqdm(alpha_list):\n",
    "        temp_model = direction_step(direction, model, a)\n",
    "        \n",
    "        eval_train = temp_model.evaluate_generator(batches)\n",
    "        eval_test = temp_model.evaluate_generator(test_batches)\n",
    "        \n",
    "        loss_train.append(eval_train[0])\n",
    "        acc_train.append(eval_train[1])\n",
    "        \n",
    "        loss_test.append(eval_test[0])\n",
    "        acc_test.append(eval_test[1])\n",
    "        \n",
    "    return loss_train, acc_train, loss_test, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sgd_train, acc_sgd_train, loss_sgd_test, acc_sgd_test = step_1d_fn(model_sgd, alpha_list, direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sgdr_train, acc_sgdr_train, loss_sgdr_test, acc_sgdr_test = step_1d_fn(model_sgdr, alpha_list, direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(alpha_list, loss_sgdr_test, label='test loss sgdr')\n",
    "plt.plot(alpha_list, loss_sgd_test, label='test loss sgd')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(alpha_list, loss_sgdr_train, label='train loss sgdr')\n",
    "plt.plot(alpha_list, loss_sgd_train, label='train loss sgd')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(alpha_list, acc_sgdr_test, label='test acc sgdr')\n",
    "plt.plot(alpha_list, acc_sgd_test, label='test acc sgd')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(alpha_list, acc_sgdr_train, label='train acc sgdr')\n",
    "plt.plot(alpha_list, acc_sgd_train, label='train acc sgd')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 2D FN plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction1 = make_direction(model_sgd)\n",
    "direction2 = make_direction(model_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.linspace(-1, 1, num=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_2d_fn(model, alpha_list, direction1, direction2):\n",
    "    loss_test, acc_test = [], []\n",
    "    \n",
    "    for a1 in tqdm(alpha_list):\n",
    "        tmp_loss, tmp_acc = [], []\n",
    "        for a2 in (alpha_list):\n",
    "            \n",
    "            temp_model = direction_step(direction1, model, a1)\n",
    "            temp_model = direction_step(direction2, temp_model, a2)\n",
    "        \n",
    "            eval_test = temp_model.evaluate_generator(test_batches)\n",
    "        \n",
    "            tmp_loss.append(eval_test[0])\n",
    "            tmp_acc.append(eval_test[1])\n",
    "            \n",
    "        loss_test.append(tmp_loss)\n",
    "        acc_test.append(tmp_acc)\n",
    "        \n",
    "    return loss_test, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sgd_test, acc_sgd_test = step_2d_fn(model_sgd, alpha_list, direction1, direction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f'{path}mnist-loss_sgd_test.npy', np.array(loss_sgd_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_sgd_test=np.load(f'{path}mnist-loss_sgd_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sgdr_test, acc_sgdr_test = step_2d_fn(model_sgdr, alpha_list, direction1, direction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f'{path}mnist-loss_sgdr_test.npy', np.array(loss_sgdr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_sgdr_test=np.load(f'{path}mnist-loss_sgdr_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "# levels = np.arange(0,18,1.5)\n",
    "# levels=(np.arange(1, 12, 1))\n",
    "c = plt.contour(alpha_list, alpha_list, loss_sgd_test)\n",
    "plt.clabel(c, inline=1, fontsize=10)\n",
    "plt.title('SGD test countour plot', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "levels=(np.arange(1, 12, 1))\n",
    "c = plt.contour(alpha_list, alpha_list, loss_sgdr_test)\n",
    "plt.clabel(c, inline=1, fontsize=10)\n",
    "plt.title('SGDR test countour plot', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Linear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_combination(model1, model2, alpha):\n",
    "    new_model = get_model()\n",
    "    w1 = model1.get_weights()\n",
    "    w2 = model2.get_weights()\n",
    "    w = []\n",
    "    for i in range(len(new_model.get_weights())):\n",
    "        w.append(alpha * w1[i] + (1-alpha) * w2[i])\n",
    "        \n",
    "    new_model.set_weights(w)\n",
    "    new_model.compile('sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = np.linspace(-1, 2, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list, acc_list = [], []\n",
    "for a in tqdm(alpha_list):\n",
    "    model_tmp = make_combination(model_sgd, model_sgdr, a)\n",
    "    loss, acc = model_tmp.evaluate_generator(batches)\n",
    "    del model_tmp\n",
    "    \n",
    "    loss_list.append(loss)\n",
    "    acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9, 6))\n",
    "plt.plot(alpha_list, acc_list, label='acc')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
